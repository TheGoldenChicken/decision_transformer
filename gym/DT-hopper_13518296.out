W&B enabled, running your script from this directory will now sync to the cloud.
Disabling Weights & Biases. Run 'wandb login' again to re-enable.
Creating states list
==================================================
Starting new experiment: hopper medium_replay
2041 trajectories, 402000 timesteps found
Average return: 467.30, std: 511.03
Max return: 3192.93, min: -1.44
==================================================
================================================================================
Iteration 1
time/training: 676.8253617286682
training/train_loss_mean: 0.24742154290974142
training/train_loss_std: 0.08693959308909958
training/action_error: 0.16898159682750702
================================================================================
Iteration 2
time/training: 676.7527136802673
training/train_loss_mean: 0.1623374572277069
training/train_loss_std: 0.012588753047996065
training/action_error: 0.14086024463176727
================================================================================
Iteration 3
time/training: 676.2673237323761
training/train_loss_mean: 0.1427999621771276
training/train_loss_std: 0.00903109187787637
training/action_error: 0.14468258619308472
================================================================================
Iteration 4
time/training: 687.8042140007019
training/train_loss_mean: 0.1324701731979847
training/train_loss_std: 0.008280171564346284
training/action_error: 0.1329459249973297
================================================================================
Iteration 5
time/training: 686.6388185024261
training/train_loss_mean: 0.12603725260943174
training/train_loss_std: 0.007475210238236101
training/action_error: 0.12947562336921692
================================================================================
Iteration 5
target_1800_return_mean: 1076.6792280283535
target_1800_return_std: 114.28760224130447
target_1800_lenght_mean: 492.0
target_1800_lenght_std: 32.13222681359012
target_1900_return_mean: 1126.3012647774322
target_1900_return_std: 203.51637774160145
target_1900_lenght_mean: 510.94
target_1900_lenght_std: 73.66177027468183
target_2000_return_mean: 1238.2419433901987
target_2000_return_std: 293.13702649957463
target_2000_lenght_mean: 555.39
target_2000_lenght_std: 118.18281558670026
target_2100_return_mean: 1478.6735698601979
target_2100_return_std: 410.459664804712
target_2100_lenght_mean: 652.77
target_2100_lenght_std: 178.49318502396667
target_2200_return_mean: 1625.2254691884996
target_2200_return_std: 409.930405225603
target_2200_lenght_mean: 698.42
target_2200_lenght_std: 172.16162057787443
target_2300_return_mean: 1797.9095306119343
target_2300_return_std: 403.1765540225545
target_2300_lenght_mean: 783.74
target_2300_lenght_std: 187.56895372102494
target_2400_return_mean: 1934.500923357897
target_2400_return_std: 427.11097015255865
target_2400_lenght_mean: 838.02
target_2400_lenght_std: 185.14907399174322
target_2500_return_mean: 2020.1603324098621
target_2500_return_std: 359.6400177343055
target_2500_lenght_mean: 888.61
target_2500_lenght_std: 160.6585755569867
target_2600_return_mean: 2063.958588510562
target_2600_return_std: 280.9217825729751
target_2600_lenght_mean: 927.84
target_2600_lenght_std: 131.03623315709285
target_2700_return_mean: 2036.8317114414197
target_2700_return_std: 304.25934137441067
target_2700_lenght_mean: 932.98
target_2700_lenght_std: 134.05416666407652
target_2800_return_mean: 2008.075599845034
target_2800_return_std: 314.71493466700315
target_2800_lenght_mean: 916.37
target_2800_lenght_std: 146.52028221376045
target_2900_return_mean: 2004.9817797720686
target_2900_return_std: 328.9829187436619
target_2900_lenght_mean: 911.22
target_2900_lenght_std: 148.4216008537841
target_3000_return_mean: 2009.010478433588
target_3000_return_std: 331.26545667227845
target_3000_lenght_mean: 911.67
target_3000_lenght_std: 147.79289935582156
target_3100_return_mean: 1878.4110904150627
target_3100_return_std: 446.2036587646509
target_3100_lenght_mean: 835.2
target_3100_lenght_std: 183.99141284309982
target_3200_return_mean: 1822.0203270453378
target_3200_return_std: 452.18159424266213
target_3200_lenght_mean: 810.22
target_3200_lenght_std: 185.84641938977464
target_3300_return_mean: 1763.759089514916
target_3300_return_std: 460.71613950201964
target_3300_lenght_mean: 782.83
target_3300_lenght_std: 184.70203328604697
target_3400_return_mean: 1773.0599873315232
target_3400_return_std: 508.62489280593405
target_3400_lenght_mean: 773.87
target_3400_lenght_std: 189.1990832430221
target_3500_return_mean: 1692.6003190671108
target_3500_return_std: 496.9639526785812
target_3500_lenght_mean: 755.39
target_3500_lenght_std: 193.86443175580197
target_3600_return_mean: 1754.7829117498093
target_3600_return_std: 521.8135891233311
target_3600_lenght_mean: 767.03
target_3600_lenght_std: 190.47201657986406
time/evaluation: 4434.965489149094
target_training/action_erro_mean: 0.12947562336921692
target_training/action_erro_std: 0.0
================================================================================
Iteration 6
time/training: 675.8166389465332
training/train_loss_mean: 0.12119339971840382
training/train_loss_std: 0.007221356114826897
training/action_error: 0.11521879583597183
================================================================================
Iteration 7
time/training: 676.2129039764404
training/train_loss_mean: 0.11755541790649295
training/train_loss_std: 0.006997011579563664
training/action_error: 0.11922664940357208
================================================================================
Iteration 8
time/training: 676.4320390224457
training/train_loss_mean: 0.11440826825574041
training/train_loss_std: 0.006770276710687385
training/action_error: 0.11319175362586975
================================================================================
Iteration 9
time/training: 677.2118799686432
training/train_loss_mean: 0.111960979963094
training/train_loss_std: 0.006557923384510792
training/action_error: 0.10994813591241837
================================================================================
Iteration 10
time/training: 676.7043724060059
training/train_loss_mean: 0.10982838531956077
training/train_loss_std: 0.006458919425242927
training/action_error: 0.10515754669904709
================================================================================
Iteration 10
target_1800_return_mean: 864.567830726454
target_1800_return_std: 381.6774771239937
target_1800_lenght_mean: 365.62
target_1800_lenght_std: 133.08078599106634
target_1900_return_mean: 905.4904243753709
target_1900_return_std: 508.81492998550044
target_1900_lenght_mean: 387.42
target_1900_lenght_std: 190.61847654411676
target_2000_return_mean: 931.7134761356438
target_2000_return_std: 530.1369357964188
target_2000_lenght_mean: 400.0
target_2000_lenght_std: 203.77409060035086
target_2100_return_mean: 1077.6217851343865
target_2100_return_std: 689.5131092618109
target_2100_lenght_mean: 467.6
target_2100_lenght_std: 277.45853744298444
target_2200_return_mean: 979.9386086060787
target_2200_return_std: 632.4775213773581
target_2200_lenght_mean: 430.13
target_2200_lenght_std: 254.8885111180965
target_2300_return_mean: 1092.9052217376648
target_2300_return_std: 729.8264878075838
target_2300_lenght_mean: 472.5
target_2300_lenght_std: 279.7085804904812
target_2400_return_mean: 1116.2455134477657
target_2400_return_std: 732.9841221459188
target_2400_lenght_mean: 478.69
target_2400_lenght_std: 280.9539711411818
target_2500_return_mean: 1101.2944793255203
target_2500_return_std: 728.3010191832249
target_2500_lenght_mean: 470.92
target_2500_lenght_std: 281.30270812773915
target_2600_return_mean: 1052.2312587721406
target_2600_return_std: 654.6083622200423
target_2600_lenght_mean: 449.01
target_2600_lenght_std: 252.5418181212767
target_2700_return_mean: 1242.453879364027
target_2700_return_std: 766.1811923655524
target_2700_lenght_mean: 525.42
target_2700_lenght_std: 297.8375120766355
target_2800_return_mean: 1079.2162320173054
target_2800_return_std: 724.2976078822467
target_2800_lenght_mean: 474.56
target_2800_lenght_std: 292.46426516755855
target_2900_return_mean: 1125.001336569756
target_2900_return_std: 709.7503403862487
target_2900_lenght_mean: 478.29
target_2900_lenght_std: 277.62522561899885
target_3000_return_mean: 1108.122859711948
target_3000_return_std: 680.2523083442164
target_3000_lenght_mean: 468.32
target_3000_lenght_std: 264.6204784214555
target_3100_return_mean: 1062.5204406223604
target_3100_return_std: 677.4684368537523
target_3100_lenght_mean: 467.72
target_3100_lenght_std: 278.76427604698563
target_3200_return_mean: 1198.7830519309118
target_3200_return_std: 774.5220423276169
target_3200_lenght_mean: 500.04
target_3200_lenght_std: 290.88980456523393
target_3300_return_mean: 1232.9886079402338
target_3300_return_std: 740.6308475793129
target_3300_lenght_mean: 516.95
target_3300_lenght_std: 292.3128589371326
target_3400_return_mean: 1091.9340786099608
target_3400_return_std: 666.0708370980747
target_3400_lenght_mean: 472.89
target_3400_lenght_std: 274.1316068971252
target_3500_return_mean: 1014.3207076072005
target_3500_return_std: 596.906074249425
target_3500_lenght_mean: 434.55
target_3500_lenght_std: 237.5643649624245
target_3600_return_mean: 1152.4146364340152
target_3600_return_std: 700.2601697201892
target_3600_lenght_mean: 493.58
target_3600_lenght_std: 284.80263973495755
time/evaluation: 2630.27086019516
target_training/action_erro_mean: 0.10515754669904709
target_training/action_erro_std: 0.0
================================================================================
Iteration 11
time/training: 674.923662185669
training/train_loss_mean: 0.10806178823560476
training/train_loss_std: 0.006437696741709378
training/action_error: 0.10654187202453613
================================================================================
Iteration 12
time/training: 677.5078418254852
training/train_loss_mean: 0.10645272202268243
training/train_loss_std: 0.006204037842104375
training/action_error: 0.10592389106750488
================================================================================
Iteration 13
time/training: 678.7248733043671
training/train_loss_mean: 0.104838665445894
training/train_loss_std: 0.006113766524556754
training/action_error: 0.10862354189157486
================================================================================
Iteration 14
time/training: 676.7211692333221
training/train_loss_mean: 0.1036728346504271
training/train_loss_std: 0.005975965900332235
training/action_error: 0.10324131697416306
================================================================================
Iteration 15
time/training: 675.490142583847
training/train_loss_mean: 0.10262345790266991
training/train_loss_std: 0.006021998446233599
training/action_error: 0.10522650182247162
================================================================================
Iteration 15
target_1800_return_mean: 2279.51862222188
target_1800_return_std: 355.74605779315675
target_1800_lenght_mean: 934.3
target_1800_lenght_std: 119.74343405798918
target_1900_return_mean: 2357.7324043423437
target_1900_return_std: 345.4167804509436
target_1900_lenght_mean: 943.69
target_1900_lenght_std: 111.71389304826862
target_2000_return_mean: 2420.2518743454298
target_2000_return_std: 294.30442233440135
target_2000_lenght_mean: 957.51
target_2000_lenght_std: 96.74983152440112
target_2100_return_mean: 2280.23445168611
target_2100_return_std: 531.4405749270742
target_2100_lenght_mean: 889.61
target_2100_lenght_std: 207.69433766956672
target_2200_return_mean: 2390.8947316833846
target_2200_return_std: 456.74747983541187
target_2200_lenght_mean: 921.54
target_2200_lenght_std: 170.41892031109694
target_2300_return_mean: 2418.6063265338885
target_2300_return_std: 488.065778781197
target_2300_lenght_mean: 912.22
target_2300_lenght_std: 187.28195748656623
target_2400_return_mean: 2419.6697335459876
target_2400_return_std: 415.9734636635005
target_2400_lenght_mean: 948.93
target_2400_lenght_std: 150.60818404057596
target_2500_return_mean: 2499.533427644889
target_2500_return_std: 331.8218221198856
target_2500_lenght_mean: 949.29
target_2500_lenght_std: 118.18961841041708
target_2600_return_mean: 2585.878192304101
target_2600_return_std: 429.03015762804307
target_2600_lenght_mean: 960.58
target_2600_lenght_std: 137.37606632889154
target_2700_return_mean: 2514.2435002351094
target_2700_return_std: 487.7819200488809
target_2700_lenght_mean: 923.24
target_2700_lenght_std: 175.0551981518972
target_2800_return_mean: 2529.9479672085254
target_2800_return_std: 437.3041246573038
target_2800_lenght_mean: 935.61
target_2800_lenght_std: 152.3394824068928
target_2900_return_mean: 2610.2965583206665
target_2900_return_std: 432.38945422718746
target_2900_lenght_mean: 937.06
target_2900_lenght_std: 140.8040354535338
target_3000_return_mean: 2435.822338910519
target_3000_return_std: 676.81288896267
target_3000_lenght_mean: 895.59
target_3000_lenght_std: 234.60695194303173
target_3100_return_mean: 2380.313784409399
target_3100_return_std: 690.969271256651
target_3100_lenght_mean: 892.28
target_3100_lenght_std: 244.3608430170431
target_3200_return_mean: 2539.7566753672522
target_3200_return_std: 469.7339900158402
target_3200_lenght_mean: 932.99
target_3200_lenght_std: 149.29330159119667
target_3300_return_mean: 2495.4358789653056
target_3300_return_std: 606.250905789859
target_3300_lenght_mean: 930.52
target_3300_lenght_std: 203.03539001858763
target_3400_return_mean: 2437.211874996786
target_3400_return_std: 502.39626035534116
target_3400_lenght_mean: 937.4
target_3400_lenght_std: 176.3156827965113
target_3500_return_mean: 2457.823913567201
target_3500_return_std: 545.8796237400674
target_3500_lenght_mean: 937.83
target_3500_lenght_std: 185.49501637510372
target_3600_return_mean: 2354.760926891501
target_3600_return_std: 620.4020849828253
target_3600_lenght_mean: 915.43
target_3600_lenght_std: 221.28069301229155
time/evaluation: 5299.576056480408
target_training/action_erro_mean: 0.10522650182247162
target_training/action_erro_std: 0.0

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 13518296: <DT-hopper> in cluster <dcc> Done

Job <DT-hopper> was submitted from host <n-62-30-4> by user <s204131> in cluster <dcc> at Sat Apr 30 15:07:23 2022
Job was executed on host(s) <4*n-62-11-15>, in queue <gpuv100>, as user <s204131> in cluster <dcc> at Sat Apr 30 15:07:24 2022
</zhome/94/3/155767> was used as the home directory.
</zhome/94/3/155767/decision_transformer/gym> was used as the working directory.
Started at Sat Apr 30 15:07:24 2022
Terminated at Sat Apr 30 21:23:55 2022
Results reported at Sat Apr 30 21:23:55 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J DT-hopper
#BSUB -o DT-hopper_%J.out
#BSUB -e DT-hopper_%J.err
#BSUB -q gpuv100
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -n 4
#BSUB -R "rusage[mem=4G]"
#BSUB -R "span[hosts=1]"
#BSUB -W 15:00
# end of BSUB options


# load CUDA (for GPU support)

# activate the virtual environment
source $HOME/miniconda3/envs/decision-transformer-gym/bin/activate

wandb on
echo 'cad8b043f3731a2c453efd8f61915e186ac93ac3' | wandb login

python experiment.py --env 'hopper' --dataset 'medium_replay' --save_iters '5,10,11,12,13,14,15' --eval_iters '5,10,15' --max_iters 15 --device 'cuda' --log_to_wandb True

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   22613.06 sec.
    Max Memory :                                 2455 MB
    Average Memory :                             2441.34 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               13929.00 MB
    Max Swap :                                   -
    Max Processes :                              6
    Max Threads :                                21
    Run time :                                   22591 sec.
    Turnaround time :                            22592 sec.

The output (if any) is above this job summary.



PS:

Read file <DT-hopper_13518296.err> for stderr output of this job.

