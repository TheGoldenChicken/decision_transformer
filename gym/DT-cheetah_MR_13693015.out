W&B enabled, running your script from this directory will now sync to the cloud.
Disabling Weights & Biases. Run 'wandb login' again to re-enable.
Creating states list
==================================================
Starting new experiment: halfcheetah medium_replay
202 trajectories, 201798 timesteps found
Average return: 3090.42, std: 1678.82
Max return: 4981.30, min: -636.89
==================================================
================================================================================
Iteration 1
time/training: 402.61183619499207
training/train_loss_mean: 0.23937853100448847
training/train_loss_std: 0.13906589199643335
training/action_error: 0.15628226101398468
================================================================================
Iteration 2
time/training: 403.4348554611206
training/train_loss_mean: 0.1302398251272738
training/train_loss_std: 0.016933063175261876
training/action_error: 0.10631952434778214
================================================================================
Iteration 3
time/training: 403.3818130493164
training/train_loss_mean: 0.11168254786878824
training/train_loss_std: 0.013852569293583496
training/action_error: 0.11192169785499573
================================================================================
Iteration 4
time/training: 404.93195033073425
training/train_loss_mean: 0.10243817681521178
training/train_loss_std: 0.012747373753373259
training/action_error: 0.10476258397102356
================================================================================
Iteration 5
time/training: 405.83824467658997
training/train_loss_mean: 0.09581719046197831
training/train_loss_std: 0.011751564310194232
training/action_error: 0.09719496220350266
================================================================================
Iteration 6
time/training: 405.8598484992981
training/train_loss_mean: 0.09112659939602018
training/train_loss_std: 0.011060817336601999
training/action_error: 0.07429246604442596
================================================================================
Iteration 7
time/training: 405.2257134914398
training/train_loss_mean: 0.08696266410127282
training/train_loss_std: 0.010279530266901003
training/action_error: 0.09258582442998886
================================================================================
Iteration 8
time/training: 402.29657649993896
training/train_loss_mean: 0.08355788949504495
training/train_loss_std: 0.009576331201002633
training/action_error: 0.07185602933168411
================================================================================
Iteration 8
returns

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 13693015: <DT-cheetah_MR> in cluster <dcc> Exited

Job <DT-cheetah_MR> was submitted from host <n-62-30-7> by user <s204131> in cluster <dcc> at Thu Jun  9 19:39:14 2022
Job was executed on host(s) <4*n-62-20-11>, in queue <gpuv100>, as user <s204131> in cluster <dcc> at Thu Jun  9 19:39:15 2022
</zhome/94/3/155767> was used as the home directory.
</zhome/94/3/155767/decision_transformer/gym> was used as the working directory.
Started at Thu Jun  9 19:39:15 2022
Terminated at Thu Jun  9 22:07:39 2022
Results reported at Thu Jun  9 22:07:39 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J DT-cheetah_MR
#BSUB -o DT-cheetah_MR_%J.out
#BSUB -e DT-cheetah_MR_%J.err
#BSUB -q gpuv100
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -n 4
#BSUB -R "rusage[mem=4G]"
#BSUB -R "span[hosts=1]"
#BSUB -W 24:00
# end of BSUB options


# load CUDA (for GPU support)

# activate the virtual environment
source $HOME/miniconda3/envs/decision-transformer-gym/bin/activate

wandb on
echo 'cad8b043f3731a2c453efd8f61915e186ac93ac3' | wandb login

python experiment_multiple_rewards.py --env 'halfcheetah' --dataset 'medium_replay' --save_iters '5,10,11,12' --eval_iters '8,9,10,11,12' --max_iters 12 --device 'cuda' --split_reward True --seed 42 --num_eval_episodes 20 --num_steps_per_iter 10000

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   8860.03 sec.
    Max Memory :                                 2694 MB
    Average Memory :                             2461.38 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               13690.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   8991 sec.
    Turnaround time :                            8905 sec.

The output (if any) is above this job summary.



PS:

Read file <DT-cheetah_MR_13693015.err> for stderr output of this job.

