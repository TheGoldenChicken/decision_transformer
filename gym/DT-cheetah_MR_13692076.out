W&B enabled, running your script from this directory will now sync to the cloud.
Disabling Weights & Biases. Run 'wandb login' again to re-enable.
Creating states list
==================================================
Starting new experiment: halfcheetah medium_replay
202 trajectories, 201798 timesteps found
Average return: 3090.42, std: 1678.82
Max return: 4981.30, min: -636.89
==================================================
================================================================================
Iteration 1
time/training: 1.1973912715911865
training/train_loss_mean: 0.8347457855939865
training/train_loss_std: 0.011691223421669308
training/action_error: 0.8497899174690247
================================================================================
Iteration 2
time/training: 0.8534057140350342
training/train_loss_mean: 0.8392592400312424
training/train_loss_std: 0.012128807877867525
training/action_error: 0.8431572318077087
================================================================================
Iteration 3
time/training: 0.8434367179870605
training/train_loss_mean: 0.8355296045541764
training/train_loss_std: 0.010580581280849283
training/action_error: 0.8299866914749146
================================================================================
Iteration 4
time/training: 0.8535292148590088
training/train_loss_mean: 0.8367436319589615
training/train_loss_std: 0.011300452658209012
training/action_error: 0.8325713276863098
================================================================================
Iteration 5
time/training: 0.8513238430023193
training/train_loss_mean: 0.832664144039154
training/train_loss_std: 0.011368475430274897
training/action_error: 0.8305253982543945
================================================================================
Iteration 6
time/training: 0.8585681915283203
training/train_loss_mean: 0.8288580805063248
training/train_loss_std: 0.014609384807148344
training/action_error: 0.8465868234634399
================================================================================
Iteration 7
time/training: 0.860388994216919
training/train_loss_mean: 0.8201887160539627
training/train_loss_std: 0.012063250768511993
training/action_error: 0.8181566596031189
================================================================================
Iteration 8
time/training: 0.8639125823974609
training/train_loss_mean: 0.8087864279747009
training/train_loss_std: 0.009970292918048391
training/action_error: 0.7971906661987305

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 13692076: <DT-cheetah_MR> in cluster <dcc> Exited

Job <DT-cheetah_MR> was submitted from host <n-62-30-7> by user <s204131> in cluster <dcc> at Thu Jun  9 13:04:36 2022
Job was executed on host(s) <4*n-62-20-12>, in queue <gpuv100>, as user <s204131> in cluster <dcc> at Thu Jun  9 13:04:38 2022
</zhome/94/3/155767> was used as the home directory.
</zhome/94/3/155767/decision_transformer/gym> was used as the working directory.
Started at Thu Jun  9 13:04:38 2022
Terminated at Thu Jun  9 13:35:01 2022
Results reported at Thu Jun  9 13:35:01 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -J DT-cheetah_MR
#BSUB -o DT-cheetah_MR_%J.out
#BSUB -e DT-cheetah_MR_%J.err
#BSUB -q gpuv100
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -n 4
#BSUB -R "rusage[mem=4G]"
#BSUB -R "span[hosts=1]"
#BSUB -W 24:00
# end of BSUB options


# load CUDA (for GPU support)

# activate the virtual environment
source $HOME/miniconda3/envs/decision-transformer-gym/bin/activate

wandb on
echo 'cad8b043f3731a2c453efd8f61915e186ac93ac3' | wandb login

python experiment_multiple_rewards.py --env 'halfcheetah' --dataset 'medium_replay' --save_iters '5,10,11,12' --eval_iters '8,9,10,11,12' --max_iters 12 --device 'cuda' --split_reward True --seed 42 --num_eval_episodes 10 --num_steps_per_iter 20

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   1790.10 sec.
    Max Memory :                                 2398 MB
    Average Memory :                             2239.80 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               13986.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   1853 sec.
    Turnaround time :                            1825 sec.

The output (if any) is above this job summary.



PS:

Read file <DT-cheetah_MR_13692076.err> for stderr output of this job.

